const express = require('express');
const bodyParser = require('body-parser');
const axios = require('axios');
const FormData = require('form-data');
const pdfParse = require('pdf-parse');
const { OpenAI } = require('openai');
const { ImageAnnotatorClient } = require('@google-cloud/vision');
require('dotenv').config();

const app = express();
app.use(bodyParser.json());

// Initialize clients
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const visionClient = new ImageAnnotatorClient();

// Environment variables
const WPP_URL = process.env.WPP_URL;
const GRUPO_GESTORES_ID = process.env.GRUPO_GESTORES_ID;

// Mapping of sellers
const VENDEDORES = {
  'cindy loren': '5562994671766',
  'ana clara martins': '5562991899053',
  'emily sequeira': '5562981704171',
  'fernando fonseca': '5562985293035'
};

// Alert templates
const MENSAGENS = {
  alerta1: (c, v) =>
    `‚ö†Ô∏è *Alerta de Atraso - Or√ßamento*\n\nPrezada(o) *${v}*, o cliente *${c}* aguarda or√ßamento h√° 6h √∫teis.\nSolicitamos aten√ß√£o para concluir o atendimento o quanto antes.\nAgradecemos pela colabora√ß√£o.`,
  alerta2: (c, v) =>
    `‚è∞ *Segundo Alerta - Or√ßamento em Espera*\n\nPrezada(o) *${v}*, refor√ßamos que o cliente *${c}* permanece aguardando or√ßamento h√° 12h √∫teis.\nSolicitamos provid√™ncias imediatas para evitar impacto negativo no atendimento.`,
  alertaFinal: (c, v) =>
    `‚ÄºÔ∏è *√öltimo Alerta (18h √∫teis)*\n\nPrezada(o) *${v}*, o cliente *${c}* est√° h√° 18h √∫teis aguardando or√ßamento.\nVoc√™ tem 10 minutos para responder esta mensagem.`,
  alertaGestores: (c, v) =>
    `üö® *ALERTA CR√çTICO DE ATENDIMENTO*\n\nCliente *${c}* segue sem retorno ap√≥s 18h √∫teis.\nRespons√°vel: *${v}*\n\n‚ö†Ô∏è Por favor, verificar esse caso com urg√™ncia.`
};

// Calculate business hours between two dates
function horasUteisEntreDatas(inicio, fim) {
  const start = new Date(inicio);
  const end = new Date(fim);
  let horas = 0;
  const cur = new Date(start);
  while (cur < end) {
    const dia = cur.getDay();
    const hora = cur.getHours();
    if (dia >= 1 && dia <= 5 && hora >= 8 && hora < 19) horas++;
    cur.setHours(cur.getHours() + 1);
  }
  return horas;
}

// Send WhatsApp message
async function enviarMensagem(numero, texto) {
  if (!numero || !/^[0-9]{11,13}$/.test(numero)) {
    console.warn(`[ERRO] N√∫mero inv√°lido: ${numero}`);
    return;
  }
  try {
    await axios.post(`${WPP_URL}/send-message`, { number: numero, message: texto });
    console.log(`Mensagem enviada para ${numero}: ${texto}`);
  } catch (err) {
    console.error('Erro ao enviar mensagem:', err.response?.data || err.message);
  }
}

// Transcribe audio via Whisper
async function transcreverAudio(url) {
  try {
    const resp = await axios.get(url, { responseType: 'arraybuffer' });
    const form = new FormData();
    form.append('file', Buffer.from(resp.data), { filename: 'audio.ogg', contentType: 'audio/ogg' });
    form.append('model', 'whisper-1');
    const result = await axios.post(
      'https://api.openai.com/v1/audio/transcriptions',
      form,
      { headers: { ...form.getHeaders(), Authorization: `Bearer ${process.env.OPENAI_API_KEY}` } }
    );
    return result.data.text;
  } catch (err) {
    console.error('[ERRO] Transcri√ß√£o de √°udio falhou:', err.response?.data || err.message);
    return null;
  }
}

// Extract text from PDF
async function extrairTextoPDF(url) {
  try {
    const resp = await axios.get(url, { responseType: 'arraybuffer' });
    const data = await pdfParse(resp.data);
    return data.text;
  } catch (err) {
    console.error('[ERRO] PDF parse falhou:', err.message || err);
    return null;
  }
}

// Analyze image via Google Cloud Vision
async function analisarImagem(url) {
  try {
    const resp = await axios.get(url, { responseType: 'arraybuffer' });
    const [result] = await visionClient.annotateImage({
      image: { content: resp.data },
      features: [
        { type: 'LABEL_DETECTION' },
        { type: 'TEXT_DETECTION' },
        { type: 'IMAGE_PROPERTIES' }
      ]
    });
    const labels = result.labelAnnotations?.map(l => l.description).join(', ') || '';
    const text = result.textAnnotations?.[0]?.description || '';
    return `Labels: ${labels}\nTexto detectado: ${text}`;
  } catch (err) {
    console.error('[ERRO] Vision GC falhou:', err);
    return null;
  }
}

// Detect if client awaits quote
async function isWaitingForQuote(cliente, mensagem, contexto) {
  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'Voc√™ √© Gerente Comercial IA, detecte se o cliente aguarda or√ßamento.' },
        { role: 'user', content: `Cliente: ${cliente}\nMensagem: ${mensagem}${
          contexto ? '\nContexto: ' + contexto : ''
        }` }
      ]
    });
    const reply = completion.choices[0].message.content.toLowerCase();
    return reply.includes('sim') || reply.includes('aguard') || reply.includes('precisa');
  } catch (err) {
    console.error('[ERRO] An√°lise de inten√ß√£o falhou:', err);
    return false;
  }
}

// Webhook endpoint
app.post('/conversa', async (req, res) => {
  try {
    const { payload } = req.body;
    if (!payload || !payload.user || !payload.message || !payload.channel) {
      console.error('[ERRO] Payload incompleto ou evento n√£o suportado:', req.body);
      return res.status(400).json({ error: 'Payload incompleto ou evento n√£o suportado' });
    }
    const { user, message, attendant } = payload;
    const nomeCliente = user.Name;
    const nomeVendedor = attendant.Name;
    const texto = message.text || message.caption || '[attachment]';
    console.log(`[LOG] Nova mensagem recebida de ${nomeCliente}: "${texto}"`);

    let contextoExtra = '';
    if (message.type === 'audio' && message.payload?.url) {
      const t = await transcreverAudio(message.payload.url);
      if (t) { console.log('[TRANSCRICAO]', t); contextoExtra += t; }
    }
    if (message.type === 'file' && message.payload?.url && message.payload.FileName?.toLowerCase().endsWith('.pdf')) {
      const pdfText = await extrairTextoPDF(message.payload.url);
      if (pdfText) { console.log('[PDF-TEXTO]', pdfText); contextoExtra += '\n' + pdfText; }
    }
    if (message.type === 'image' && message.payload?.url) {
      const imgRes = await analisarImagem(message.payload.url);
      if (imgRes) { console.log('[IMAGEM-ANALISE]', imgRes); contextoExtra += '\n' + imgRes; }
    }

    const aguardando = await isWaitingForQuote(nomeCliente, texto, contextoExtra);
    if (!aguardando) {
      console.log('[INFO] Cliente n√£o aguarda or√ßamento. Sem alertas.');
      return res.json({ status: 'Sem a√ß√£o necess√°ria.' });
    }

    const criadoEm = new Date(message.CreatedAt || payload.timestamp);
    const horas = horasUteisEntreDatas(criadoEm, new Date());
    const numeroVendedor = VENDEDORES[nomeVendedor?.toLowerCase()];
    if (!numeroVendedor) {
      console.warn(`[ERRO] Vendedor "${nomeVendedor}" n√£o est√° mapeado.`);
      return res.json({ warning: 'Vendedor n√£o mapeado.' });
    }

    if (horas >= 18) {
      await enviarMensagem(numeroVendedor, MENSAGENS.alertaFinal(nomeCliente, nomeVendedor));
      setTimeout(() => enviarMensagem(GRUPO_GESTORES_ID, MENSAGENS.alertaGestores(nomeCliente, nomeVendedor)), 10 * 60 * 1000);
    } else if (horas >= 12) {
      await enviarMensagem(numeroVendedor, MENSAGENS.alerta2(nomeCliente, nomeVendedor));
    } else if (horas >= 6) {
      await enviarMensagem(numeroVendedor, MENSAGENS.alerta1(nomeCliente, nomeVendedor));
    }

    res.json({ status: 'Processado' });
  } catch (err) {
    console.error('[ERRO] Falha ao processar:', err);
    res.status(500).json({ error: 'Erro interno.' });
  }
});

// Start server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`Servidor rodando na porta ${PORT}`));
